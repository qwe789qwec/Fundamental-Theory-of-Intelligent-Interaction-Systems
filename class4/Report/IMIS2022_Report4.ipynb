{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kameda-yoshinari/IMISToolExeA2022/blob/main/Report/IMISToolA2022_Report4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SqpuNOEWS-a"
      },
      "source": [
        "# Report 4 (2022/08/01 ver.B)\n",
        "\n",
        "for Tools for intelligent interaction systems a (0ALE005 / 0AL5706).\n",
        "\n",
        "---\n",
        "\n",
        "* Student ID: 202120389\n",
        "* Name: wei-sheng, wang\n",
        "* Colab account: qwe789qwec@gmail.com\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NUVKBVvmvtw"
      },
      "source": [
        "# Report4A: Live capture query with CIFAR-10 or MNIST  \n",
        "\n",
        "* Show the way to build a classfier of CIFAR10 or MNIST.\n",
        "* Provide a python program that captures an image from a camera and that shows its recognition result of the image immediately.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"color:#6960EC\">Import data and dataset, set up the Parameters.</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "num_epochs = 10\n",
        "num_batch = 100\n",
        "learning_rate = 0.001\n",
        "image_size = 28*28\n",
        "\n",
        "# use cuda or cpu\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# dataset for training\n",
        "train_dataset = datasets.MNIST(\n",
        "    './data',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    )\n",
        "\n",
        "# dataset for test\n",
        "test_dataset = datasets.MNIST(\n",
        "    './data', \n",
        "    train = False,\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    )\n",
        "\n",
        "# data loader\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = num_batch,\n",
        "    shuffle = True\n",
        "    )\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset,     \n",
        "    batch_size = num_batch,\n",
        "    shuffle = True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"color:#6960EC\">Define the neural network model, loss function and optimization methods </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Instances of each class (setting input/output size, etc.)\n",
        "        self.fc1 = nn.Linear(input_size, 100)\n",
        "        self.fc2 = nn.Linear(100, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Setting up forward propagation (executing a special method (__call__) of the instantiated class)\n",
        "        x = self.fc1(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Generating Neural Networks\n",
        "model = Net(image_size, 10).to(device)\n",
        "# Setting up a loss function\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "# Setting up optimization methods\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"color:#6960EC\">Start training the model</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/10, Loss: 0.6717003377278646\n",
            "Epoch: 2/10, Loss: 0.26682955423990884\n",
            "Epoch: 3/10, Loss: 0.21055524190266928\n",
            "Epoch: 4/10, Loss: 0.1767929204305013\n",
            "Epoch: 5/10, Loss: 0.15242698669433594\n",
            "Epoch: 6/10, Loss: 0.13376462300618489\n",
            "Epoch: 7/10, Loss: 0.11820386250813802\n",
            "Epoch: 8/10, Loss: 0.1050484275817871\n",
            "Epoch: 9/10, Loss: 0.0944560432434082\n",
            "Epoch: 10/10, Loss: 0.08524284998575847\n"
          ]
        }
      ],
      "source": [
        "model.train()  # Put the model in training mode\n",
        "\n",
        "for epoch in range(num_epochs): # learning cycle\n",
        "    loss_sum = 0\n",
        "\n",
        "    for inputs, labels in train_dataloader:\n",
        "\n",
        "        # Send data to GPU if GPU is available\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Initialize optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Neural network processing.\n",
        "        inputs = inputs.view(-1, image_size) # Reorder image data portions into one dimension\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculation of loss (error between output and label)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss_sum += loss\n",
        "\n",
        "        # Gradient Calculation\n",
        "        loss.backward()\n",
        "\n",
        "        # Update Weights\n",
        "        optimizer.step()\n",
        "\n",
        "    # Display of study status\n",
        "    print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss_sum.item() / len(train_dataloader)}\")\n",
        "\n",
        "    # Model weight storage\n",
        "    torch.save(model.state_dict(), 'model_weights.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"color:#6960EC\">Evaluate the accuracy of the model</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.10391839981079101, Accuracy: 96.79% (9679/10000)\n"
          ]
        }
      ],
      "source": [
        "model.eval()  # Put the model in evaluation mode\n",
        "\n",
        "loss_sum = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_dataloader:\n",
        "\n",
        "        # Send data to GPU if GPU is available\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Neural network processing.\n",
        "        inputs = inputs.view(-1, image_size) # Reorder image data portions into one dimension\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculation of loss (error between output and label)\n",
        "        loss_sum += criterion(outputs, labels)\n",
        "\n",
        "        # Get the correct value\n",
        "        pred = outputs.argmax(1)\n",
        "        # Count the number of correct answers\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "\n",
        "print(f\"Loss: {loss_sum.item() / len(test_dataloader)}, Accuracy: {100*correct/len(test_dataset)}% ({correct}/{len(test_dataset)})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jF38tfbtz03"
      },
      "source": [
        "---\n",
        "# Report4B: Unique features of PyTorch\n",
        "\n",
        "What are the unique features of PyTorch (compared with other ML libraries)?\\\n",
        "Find appopriate part in the tutorials\\\n",
        "documents in the official pytorch www, site them, and point the features.\\\n",
        "Then summersize them totally from your viewpoint. \n",
        "\n",
        "* List up at least two unique features. (URL, sentences to fit, and short description for each)\n",
        "* Total summary would be a coule of lines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"color:#6960EC\">Another famous machine learning framework is TensorFlow, here TensorFlow will be the main object of comparison.</span>\n",
        "## Model Availability\n",
        "In recent years, [there have been more papers using PyTorch than TensorFlow](https://horace.io/pytorch-vs-tensorflow/).\\\n",
        "Perhaps because of this, PyTorch has more [SOTA models](https://huggingface.co/models) support than TensorFlow.\n",
        "## Deployment Infrastructure\n",
        "[TensorFlow Serving and TensorFlow Lite are more mature than TorchServe and PyTorch Live.](https://www.kdnuggets.com/2022/02/packt-pytorch-tensorflow-comparing-popular-machine-learning-frameworks.html)\\\n",
        "And TensorFlow's tools let you deploy painlessly on cloud, server, mobile, and IoT devices.\\\n",
        "But PyTorch has been working hard to close this gap in recent years, and maybe there will be some changes again in the next few years."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aExQhnAcClQB"
      },
      "source": [
        "---\n",
        "# Report4C: Tutorials of pytorch\n",
        "\n",
        "There are [many tutorials](https://github.com/kameda-yoshinari/IMISToolExeA2021/blob/master/300_PyTorch.ipynb) provided by the Pytorch official site. Pick up **four tutorials** (you should complete those tutorials) and make a report for the four tutorials on:\n",
        "\n",
        "* Summary (2-3 lines)\n",
        "* What you learn\n",
        "* The most difficult part\n",
        "\n",
        "Note that you can choose the first two (mandatory ones) in the four choices. \n",
        "However, you should not take all fours in basic category (at least one should be from other category). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjOgrYW8lAmy"
      },
      "source": [
        "---\n",
        "# Report4D: Chainer history  \n",
        "\n",
        "Briefly summerize the history of chainer and describe why it was coming and why it had to gone.\n",
        "\n",
        "* Who were the rivals? \n",
        "* What was the chainer's advantage?\n",
        "* What was their disadvantage (that results in their sad end)?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Z8A8xin-Ru"
      },
      "source": [
        "1.Chainer's contemporaries and more famous machine learning frameworks include Caffe, Theano and MXNet.\\\n",
        "2.Define-by-Run: This dynamic definition allows conditionals and loops into the network definitions easily.\\\n",
        "3.Ecosystems are not powerful enough. So PFN, the developer of Chainer, decided to shift its efforts to pyTorch, which has a more complete ecosystem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG38xv8ZHJUw"
      },
      "source": [
        "---\n",
        "#Report4E: Your Goole drive usage\n",
        "\n",
        "Find out the amount of your google drive space and report it.  \n",
        "Discuss the availability and what you should do to make it small.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6eNVn3PJFTM"
      },
      "source": [
        "<span style=\"color:#6960EC\">The amount of my google drive is 15G.\\\n",
        "This is almost the size of a typical 16G USB flash drive.\\\n",
        "It is very convenient to use in places where there is internet access, but it will be very inconvenient to transfer larger files if the internet speed is not fast enough.</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7rf54NjW5f2"
      },
      "source": [
        "---\n",
        "# Report submission\n",
        "\n",
        "The report template will be given in ipynb file.\n",
        "You should save it to your local google colaboratory folder and then edit it to fit your report.\n",
        "\n",
        "The report submission should be made at this cource (0ALE002) at https://manaba.tsukuba.ac.jp .\n",
        "Note that 0ALE005 is coupled with 0ALE002 (and 0AL5706) on manaba system.\n",
        "\n",
        "\n",
        "**File (main)**\n",
        "\n",
        "Download the ipynb to your local machine and then submit the file to the manaba.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrwIDJcJkSCk"
      },
      "source": [
        "---\n",
        "Tools and Practices for Intelligent Interaction Systems A  \n",
        "Master's and Docotal programs in intelligent and mechanical interaction systems, University of Tsukuba, Japan.  \n",
        "KAMEDA Yoshinari, SHIBUYA Takeshi  \n",
        "\n",
        "知能システムツール演習a  \n",
        "知能機能システム学位プログラム (筑波大学大学院)  \n",
        "担当：亀田能成，澁谷長史  \n",
        "\n",
        "2022/08/01. Ver.B. (File submission only)\n",
        "2022/08/01. Ver.A.\n",
        " \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPt0pnG2Fay11o8GzIeKqWx",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "IMISToolA2022-Report4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e1a164d0d001457449004470999f82d060d0b5fa540a19559da819ceecae7b5d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
